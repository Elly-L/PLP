{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8ea6b4",
   "metadata": {},
   "source": [
    "# ğŸ¦  CORD-19 Research Analysis â€“ Final Project\n",
    "\n",
    "This notebook contains data loading, cleaning, analysis, visualization, and a sample Streamlit app for exploring the CORD-19 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34144c5",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shape and info\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.info())\n",
    "\n",
    "# Missing values (top 10 columns with most missing)\n",
    "df.isnull().sum().sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b50ba6",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows missing key info\n",
    "df = df.dropna(subset=[\"title\", \"publish_time\"])\n",
    "\n",
    "# Convert publish_time to datetime and extract year\n",
    "df[\"publish_time\"] = pd.to_datetime(df[\"publish_time\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"publish_time\"].dt.year\n",
    "\n",
    "# Abstract word count\n",
    "df[\"abstract_word_count\"] = df[\"abstract\"].fillna(\"\").apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec96422",
   "metadata": {},
   "source": [
    "## Part 3: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Publications per year\n",
    "year_counts = df[\"year\"].value_counts().sort_index()\n",
    "year_counts.plot(kind=\"bar\", title=\"Publications by Year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top journals\n",
    "top_journals = df[\"journal\"].value_counts().head(10)\n",
    "top_journals.plot(kind=\"barh\", title=\"Top 10 Journals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Frequent words in titles\n",
    "words = \" \".join(df[\"title\"].dropna()).lower().split()\n",
    "word_counts = Counter(words)\n",
    "word_counts.most_common(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f451eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Word cloud of titles\n",
    "wc = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(words))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab620d",
   "metadata": {},
   "source": [
    "## Part 4: Streamlit Application (Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61800970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save this as app.py if you want to run it separately\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"metadata.csv\")\n",
    "df[\"publish_time\"] = pd.to_datetime(df[\"publish_time\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"publish_time\"].dt.year\n",
    "\n",
    "st.title(\"CORD-19 Data Explorer\")\n",
    "st.write(\"Interactive exploration of COVID-19 research papers\")\n",
    "\n",
    "year_range = st.slider(\"Select year range\", int(df[\"year\"].min()), int(df[\"year\"].max()), (2020, 2021))\n",
    "filtered = df[(df[\"year\"] >= year_range[0]) & (df[\"year\"] <= year_range[1])]\n",
    "\n",
    "st.write(filtered.sample(5))\n",
    "st.bar_chart(filtered[\"year\"].value_counts().sort_index())\n",
    "st.bar_chart(filtered[\"journal\"].value_counts().head(10))\n",
    "\n",
    "# Example histogram of abstract lengths\n",
    "fig, ax = plt.subplots()\n",
    "filtered[\"abstract\"].fillna(\"\").apply(lambda x: len(x.split())).hist(bins=50, ax=ax)\n",
    "ax.set_xlabel(\"Word Count\")\n",
    "ax.set_ylabel(\"Number of Papers\")\n",
    "st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2586bb4",
   "metadata": {},
   "source": [
    "## Part 5: Reflection\n",
    "- Learned data cleaning, visualization, and how to build an interactive dashboard.\n",
    "- Insight: Surge of papers in 2020, many on preprint servers.\n",
    "- Challenge: Handling missing values in abstracts and journals.\n",
    "- Takeaway: Practiced full data science workflow with Python, pandas, matplotlib, and Streamlit.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}